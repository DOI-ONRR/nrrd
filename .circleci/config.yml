version: 2.1
orbs:
  aws-s3: circleci/aws-s3@2.0.0
commands:
  load-database:
    description: "Building database"
    steps:
      - run:
          name: "Begin database build"
          command: |
            cd database
            ls -l
      - run:
          name: "Docker compose"
          command: |
            cd database
            sudo docker-compose up -d
      - run:
          name: "Update OS"
          command: sudo apt-get update
      - run:
          name: "Install posgres client"
          command: sudo apt-get install  --fix-missing  postgresql-client && cp database/.pgpass $HOME/.pgpass && chmod 0600 $HOME/.pgpass
      - run:
          name: "Restore Database schema"
          command: |
             pg_restore --verbose --user=postgres --host=localhost --clean  --no-owner --no-acl --dbname=postgres --no-password ./database/backup/database_backup.pg || echo $?
      - run:
          name: "Truncate reference data."
          no_output_timeout: 30m
          command: cd database && psql --host=localhost --user=postgres -c 'truncate period cascade; truncate location cascade; truncate commodity cascade;'
      - run:
          name: "Load Revenue"
          no_output_timeout: 30m
          command: cd database && bash ./src/ELT/monthly_revenue.load.sh
      - run:
          name: "Load Monthly Production"
          command: cd database && psql --host=localhost --user=postgres< ./src/ELT/monthly_production.load.sql
      - run:
          name: "Load Fiscal Production"
          command: cd database && psql --host=localhost --user=postgres< ./src/ELT/fiscal_year_production.load.sql
      - run:
          name: "Load Calendar Production"
          command: cd database && psql --host=localhost --user=postgres< ./src/ELT/calendar_year_production.load.sql
      - run:
          name: "Load Monthly Disbursement"
          command: cd database && psql --host=localhost --user=postgres< ./src/ELT/monthly_disbursement.load.sql
      - run:
          name: "Load Fiscal Disbursement"
          command: cd database && psql --host=localhost --user=postgres< ./src/ELT/fiscal_year_disbursement.load.sql
      - run:
          name: "Load Revenue By Company"
          command: cd database && psql --host=localhost --user=postgres < ./src/ELT/revenue_by_company.elt.sql
      - run:
          name: "Update metadata"
          command: cd database && psql --host=localhost --user=postgres < ./src/ELT/update_metadata.sql
      - run:
          name: "Refresh views"
          command: cd database && bash ./src/scripts/refresh_materialized_views.sh
      - run:
          name: "Backup database"
          command: |
            pg_dump postgres://postgres:postgrespassword@localhost:5432/postgres -Fc -f /tmp/database_backup.pg || echo $?
  generate-downloads:
    description: "generate downloads"
    steps:
      - run:
          name: "Install ssconvert"
          command: sudo apt-get install gnumeric
      - run:
          name: "Generate downloads"
          command: |
              cd database
              npm install
              bash ./src/scripts/downloads.sh
              node ./src/scripts/downloads.js
      - run:
          name: "list generated downloads"
          command: |
            ls /tmp/downloads/*
      - store_artifacts:
          path: /tmp/database_backup.pg
          destination: database_backup.pg
      - store_artifacts:
          path: /tmp/downloads
          destination: downloads
      - aws-s3/sync:
          arguments: |
          aws-access-key-id: NPS_AWS_ACCESS_KEY
          aws-region: NPS_AWS_REGION
          aws-secret-access-key: NPS_AWS_SECRET_ACCESS_KEY
          from: /tmp/downloads/
          to: 's3://$NPS_BUCKET_NAME/downloads/'
      - aws-s3/copy:
          arguments: |
          aws-access-key-id: NPS_AWS_ACCESS_KEY
          aws-region: NPS_AWS_REGION
          aws-secret-access-key: NPS_AWS_SECRET_ACCESS_KEY
          from: /tmp/database_backup.pg
          to: 's3://$NPS_BUCKET_NAME/backup/database_backup.pg'
      - run:
          name: "list bucket"
          command: |
            aws s3 ls s3://${NPS_BUCKET_NAME}/

jobs:
  lint:
    docker:
      - image: circleci/node:12.4
    working_directory: ~/repo
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          command: npm run lint
          when: always
      - store_test_results:
          path: ./test-results
      - store_artifacts:
          path: ./test-results

  unit_tests:
    docker:
      - image: circleci/node:12.13.0-browsers
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          name: Run unit tests
          command: npm run test-unit-tests
      - store_test_results:
          path: ./test-results
      - store_artifacts:
          path: ./coverage
  end_to_end_tests:
    docker:
      - image: circleci/node:12.13.0-browsers
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          name: Run end to end  tests
          command: npm run test-end-to-end
      - store_test_results:
          path: ./test-results
      - store_artifacts:
          path: ./__tests__/__image_snapshots__/
  lighthouse:
    docker:
      - image: circleci/node:12.13.0-browsers
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          name: Create lighthouse audit report
          command: node __audits__/lighthouse.audit.js
      - store_artifacts:
          path: ./__audits__/lighthouse/

  sandbox-database:
    machine:
      image: ubuntu-2004:2023.02.1
    steps:
      - checkout
      - run:
          name: "Check for database changes"
          command: |
            CHANGES=`git diff --name-only dev | grep database\/ | wc -w` || echo $?
            if [ "$CHANGES" = "0" ]; then
              echo "Halting database build -  no database changes"
              circleci-agent step halt
            fi
      - load-database
      - run:
          name: "Deploy to hasura-sandbox cloud.gov"
          command: |
            cd database
            wget -q -U "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36" -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -
            echo "deb https://packages.cloudfoundry.org/debian stable main" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list
            sudo apt-get update
            sudo apt-get install cf8-cli
            cf api https://api.fr.cloud.gov
            echo "$CF_USERNAME"
            cf auth "$CF_USERNAME" "$CF_PASSWORD"
            cf target -o "$CF_ORG" -s "$CF_SPACE"
            cf apps
            cf install-plugin -f https://github.com/cloud-gov/cf-service-connect/releases/download/1.1.0/cf-service-connect-linux-amd64
            bash tunnel.sh hasura-sandbox-interface
            source ./.tunnelrc
            cat ./.tunnelrc
            psql --user=$Username --host=$Host --port=$Port --dbname=$Name -c 'drop owned by current_user cascade; create schema public;'
            pg_restore --user=$Username --host=$Host --port=$Port --clean  --no-owner --no-acl --dbname=$Name --no-password /tmp/database_backup.pg || echo $?
            cf restage hasura-sandbox
      - generate-downloads
  dev-database:
    machine:
      image: ubuntu-2004:2023.02.1
    steps:
      - checkout
      - run:
          name: "Check for database changes"
          command: |
            CHANGES=`git log -m --name-only | grep database\/ | wc -w` || echo $?
            if [ "$CHANGES" = "0" ]; then
              echo "Halting database build -  no database changes"
              circleci-agent step halt
            fi
      - load-database
      - run:
          name: "Deploy to cloud.gov"
          command: |
            cd database
            wget -q -U "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36" -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -
            echo "deb https://packages.cloudfoundry.org/debian stable main" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list
            sudo apt-get update
            sudo apt-get install cf8-cli
            cf api https://api.fr.cloud.gov
            echo "$CF_USERNAME"
            cf auth "$CF_USERNAME" "$CF_PASSWORD"
            cf target -o doi-onrr -s prod
            cf apps
            cf install-plugin -f https://github.com/cloud-gov/cf-service-connect/releases/download/1.1.0/cf-service-connect-linux-amd64
            bash tunnel.sh hasura-dev-interface
            source ./.tunnelrc
            cat ./.tunnelrc
            psql --user=$Username --host=$Host --port=$Port --dbname=$Name -c 'drop owned by current_user cascade; create schema public;'
            pg_restore --user=$Username --host=$Host --port=$Port --clean  --no-owner --no-acl --dbname=$Name --no-password /tmp/database_backup.pg || echo $?
            cf restage hasura-dev
      - generate-downloads
  prod-database:
    machine:
      image: ubuntu-2004:2023.02.1
    steps:
      - checkout
      - run:
          name: "Check for database changes"
          command: |
            CHANGES=`git log -m --name-only | grep database\/ | wc -w` || echo $?
            if [ "$CHANGES" = "0" ]; then
              echo "Halting database build -  no database changes"
              circleci-agent step halt
            fi
      - load-database
      - run:
          name: "Deploy to cloud.gov"
          command: |
            cd database
            wget -q -U "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36" -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -
            echo "deb https://packages.cloudfoundry.org/debian stable main" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list
            sudo apt-get update
            sudo apt-get install cf8-cli
            cf api https://api.fr.cloud.gov
            echo "$CF_USERNAME"
            cf auth "$CF_USERNAME" "$CF_PASSWORD"
            cf target -o doi-onrr -s prod
            cf apps
            cf install-plugin -f https://github.com/cloud-gov/cf-service-connect/releases/download/1.1.0/cf-service-connect-linux-amd64
            bash tunnel.sh hasura-prod-interface
            source ./.tunnelrc
            cat ./.tunnelrc
            psql --user=$Username --host=$Host --port=$Port --dbname=$Name -c 'drop owned by current_user cascade; create schema public;'
            pg_restore --user=$Username --host=$Host --port=$Port --clean  --no-owner --no-acl --dbname=$Name --no-password /tmp/database_backup.pg || echo $?
            cf restage hasura-dev
      - generate-downloads
  nrrd-preview:
    docker:
      # This image has the latest cf-cli as well as zero downtime plugins, if needed.
      - image: circleci/node:12.13.0
    resource_class: medium+
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          command: |
            ls -lart static/downloads
      - aws-s3/sync:
          arguments: |
          aws-access-key-id: NPS_AWS_ACCESS_KEY
          aws-region: NPS_AWS_REGION
          aws-secret-access-key: NPS_AWS_SECRET_ACCESS_KEY
          from: 's3://${NPS_BUCKET_NAME}/downloads/'
          to: static/downloads/
      - run:
          command: |
            ls -lart static/downloads
      - run:
          name: Build gatsby
          command: export GATSBY_HASURA_URI=https://hasura-sandbox.app.cloud.gov/v1/graphql &&  export CIRCLE_STAGE='nrrd-preview' && npm run build
      - aws-s3/sync:
          aws-access-key-id: NPS_AWS_ACCESS_KEY
          aws-region: NPS_AWS_REGION
          aws-secret-access-key: NPS_AWS_SECRET_ACCESS_KEY
          from: public
          to: 's3://$NPS_BUCKET_NAME/sites/$CIRCLE_BRANCH'
      - run:
          command: |
                ls -lart static/downloads
      - run:
          name: clean up
          command: |
            bash ./.circleci/cleanup-previews.sh
  dev:
    docker:
      - image: cimg/node:12.13-browsers
    resource_class: medium+
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          name: "list generated downloads"
          command: |
            ls -lart static/downloads
           # rm static/downloads/downloads.json
      - aws-s3/sync:
          arguments: |
          aws-access-key-id: NPS_AWS_ACCESS_KEY
          aws-region: NPS_AWS_REGION
          aws-secret-access-key: NPS_AWS_SECRET_ACCESS_KEY
          from: 's3://${NPS_BUCKET_NAME}/downloads/'
          to: static/downloads/
      - run:
          name: "list generated downloads"
          command: |
            ls -lart static/downloads
            cat static/downloads/downloads.json
      - run:
          name: Build gatsby
          command: export GATSBY_HASURA_URI=https://hasura-dev.app.cloud.gov/v1/graphql && npm run build
      - run:
          name: deploy to cloud.gov
          command: |
            pwd && ls -l
            wget -q -U "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36" -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -
            echo "deb https://packages.cloudfoundry.org/debian stable main" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list
            sudo apt-get update
            sudo apt-get install cf8-cli
            cp Staticfile ./public
            cf api https://api.fr.cloud.gov
            cf login -u "$CF_USERNAME" -p "$CF_PASSWORD" -a api.fr.cloud.gov -o doi-onrr -s dev -v
            cf push dev-nrrd -f ./manifest.yml
  prod:
    docker:
      # This image has the latest cf-cli as well as zero downtime plugins, if needed.
      - image: cimg/node:12.13-browsers
    resource_class: medium+
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          name: "list generated downloads"
          command: |
            ls -lart static/downloads
           # rm static/downloads/downloads.json
      - aws-s3/sync:
          arguments: |
          aws-access-key-id: NPS_AWS_ACCESS_KEY
          aws-region: NPS_AWS_REGION
          aws-secret-access-key: NPS_AWS_SECRET_ACCESS_KEY
          from: 's3://${NPS_BUCKET_NAME}/downloads/'
          to: static/downloads/
      - run:
          name: "list generated downloads"
          command: |
            ls -lart static/downloads
            cat static/downloads/downloads.json
      - run:
          name: Build gatsby
          command: export GATSBY_HASURA_URI=https://hasura-prod.app.cloud.gov/v1/graphql && npm run build
      - run:
          name: deploy preview to cloud.gov
          command: |
            pwd && ls -l
            wget -q -U "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36" -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -
            echo "deb https://packages.cloudfoundry.org/debian stable main" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list
            sudo apt-get update
            sudo apt-get install cf8-cli
            cp Staticfile ./public
            # Set $CF_USERNAME and $CF_PASSWORD in CircleCI settings.
            # $CF_ORG, $CF_SPACE, and $APP_NAME can also be set in CircleCI settings or hardcoded here.
            cf api https://api.fr.cloud.gov
            cf auth "$CF_USERNAME" "$CF_PASSWORD"
            cf target -o doi-onrr -s prod
            #bash ./swap.sh
            cf push nrrd -f ./manifest.yml
workflows:
  audits:
    jobs:
      - unit_tests:
          filters:
            branches:
              ignore:
                - master
                - staging
      - lint:
          filters:
            branches:
              ignore:
                - master
                - staging

      - lighthouse:
          filters:
            branches:
              ignore:
                - master
                - staging
  preview:
    jobs:
      - sandbox-database:
          context:
            - org-global
            - nrrd
            - DEV
          filters:
            branches:
              ignore:
                - master
                - dev
      - nrrd-preview:
          context:
            - nrrd
          requires:
            - sandbox-database
          filters:
            branches:
              ignore:
                - master
                - dev

  prod:
    jobs:
      - prod-database:
          context:
            - org-global
            - nrrd
          filters:
            branches:
              only: master
      - prod:
          context:
            - org-global
            - nrrd
          requires:
            - prod-database
          filters:
            branches:
              only: master
  dev:
    jobs:
      - dev-database:
          context:
            - org-global
            - nrrd
          filters:
            branches:
              only: dev
      - dev:
          context:
            - org-global
            - nrrd
          requires:
            - dev-database
          filters:
            branches:
              only: dev
      # - end_to_end_tests:
      #     requires:
      #       - dev