version: 2.1

parameters:
  run_generate_downloads:
    type: boolean
    default: false
  env_context:
    type: string
    default: PREVIEW

orbs:
  aws-s3: circleci/aws-s3@2.0.0
  node: circleci/node@5.1.0

commands:
  install-cf-cli:
    description: "Install cloud foundry cli"
    steps:
      - run:
          name: Download cf cli package and install
          command: |
            wget -q -U "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36" -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -
            echo "deb https://packages.cloudfoundry.org/debian stable main" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list
            sudo apt-get update
            sudo apt-get install cf8-cli
  install-liquibase:
    description: Install liquibase
    steps:
      - run:
          name: Download liquibase and install
          command: |
            wget -O- https://repo.liquibase.com/liquibase.asc | gpg --dearmor > liquibase-keyring.gpg && \
            cat liquibase-keyring.gpg | sudo tee /usr/share/keyrings/liquibase-keyring.gpg > /dev/null && \
            echo 'deb [arch=amd64 signed-by=/usr/share/keyrings/liquibase-keyring.gpg] https://repo.liquibase.com stable main' | sudo tee /etc/apt/sources.list.d/liquibase.list
            sudo apt-get update
            sudo apt-get install liquibase
  install-java:
    description: Install Java
    steps:
      - run:
          name: Install Java 
          command: |
            sudo apt-get update
            sudo apt-get install default-jre
  install-postgres-client:
    description: Install postgres client tools
    steps:
      - run:
          name: Install postgres client tools
          command: |
            sudo apt-get install --fix-missing  postgresql-client
  generate-downloads:
    description: "generate downloads"
    steps:
      - run:
          name: "Install gnumeric"
          command: |
            sudo apt-get install --no-install-recommends gnumeric
      - run:
          name: "Generate downloads"
          command: |
              cd database
              npm install
              bash ./src/scripts/downloads.sh
              node ./src/scripts/downloads.js --host $HOST --port $PORT --username $USERNAME --password $PASSWORD --database $DB_NAME
      - run:
          name: "list generated downloads"
          command: |
            ls /tmp/downloads/*
      - store_artifacts:
          path: /tmp/downloads
          destination: downloads
      - aws-s3/sync:
          arguments: |
          aws-access-key-id: NPS_AWS_ACCESS_KEY
          aws-region: NPS_AWS_REGION
          aws-secret-access-key: NPS_AWS_SECRET_ACCESS_KEY
          from: /tmp/downloads/
          to: 's3://$NPS_BUCKET_NAME/downloads/'
      - run:
          name: "list bucket"
          command: |
            aws s3 ls s3://${NPS_BUCKET_NAME}/

jobs:
  lint:
    docker:
      - image: cimg/node:12.4
    working_directory: ~/repo
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          command: npm run lint
          when: always
      - store_test_results:
          path: ./test-results
      - store_artifacts:
          path: ./test-results
  unit_tests:
    docker:
      - image: cimg/node:12.13-browsers
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          name: Run unit tests
          command: npm run test-unit-tests
      - store_test_results:
          path: ./test-results
      - store_artifacts:
          path: ./coverage
  end_to_end_tests:
    docker:
      - image: cimg/node:12.13-browsers
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          name: Run end to end  tests
          command: npm run test-end-to-end
      - store_test_results:
          path: ./test-results
      - store_artifacts:
          path: ./__tests__/__image_snapshots__/
  lighthouse:
    docker:
      - image: cimg/node:12.13-browsers
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          name: Create lighthouse audit report
          command: node __audits__/lighthouse.audit.js
      - store_artifacts:
          path: ./__audits__/lighthouse/
  nrrd-preview:
    docker:
      - image: cimg/node:16.20-browsers
    resource_class: xlarge
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          command: |
            ls -lart static/downloads
      - aws-s3/sync:
          arguments: |
          aws-access-key-id: NPS_AWS_ACCESS_KEY
          aws-region: NPS_AWS_REGION
          aws-secret-access-key: NPS_AWS_SECRET_ACCESS_KEY
          from: 's3://${NPS_BUCKET_NAME}/downloads/'
          to: static/downloads/
      - run:
          command: |
            ls -lart static/downloads
      - run:
          name: Overwrite robots.txt
          command: |
            cp ./static/robots-dev.txt ./static/robots.txt
      - run:
          name: Build gatsby
          command: export GATSBY_HASURA_URI=https://hasura-sandbox.app.cloud.gov/v1/graphql &&  export CIRCLE_STAGE='nrrd-preview' && npm run build
      - aws-s3/sync:
          aws-access-key-id: NPS_AWS_ACCESS_KEY
          aws-region: NPS_AWS_REGION
          aws-secret-access-key: NPS_AWS_SECRET_ACCESS_KEY
          from: public
          to: 's3://$NPS_BUCKET_NAME/sites/$CIRCLE_BRANCH'
      - run:
          command: |
                ls -lart static/downloads
      - run:
          name: clean up
          command: |
            bash ./.circleci/cleanup-previews.sh
  dev:
    docker:
      - image: cimg/node:16.20-browsers
    resource_class: xlarge
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          name: "list generated downloads"
          command: |
            ls -lart static/downloads
      - aws-s3/sync:
          arguments: |
          aws-access-key-id: NPS_AWS_ACCESS_KEY
          aws-region: NPS_AWS_REGION
          aws-secret-access-key: NPS_AWS_SECRET_ACCESS_KEY
          from: 's3://${NPS_BUCKET_NAME}/downloads/'
          to: static/downloads/
      - run:
          name: "list generated downloads"
          command: |
            ls -lart static/downloads
            cat static/downloads/downloads.json
      - run:
          name: Overwrite robots.txt
          command: |
            cp ./static/robots-dev.txt ./static/robots.txt
      - run:
          name: Build gatsby
          command: export GATSBY_HASURA_URI=https://hasura-dev.app.cloud.gov/v1/graphql && npm run build
      - run:
          name: deploy to cloud.gov
          command: |
            pwd && ls -l
            wget -q -U "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36" -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -
            echo "deb https://packages.cloudfoundry.org/debian stable main" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list
            sudo apt-get update
            sudo apt-get install cf8-cli
            cp Staticfile ./public
            cf api https://api.fr.cloud.gov
            cf login -u "$CF_USERNAME" -p "$CF_PASSWORD" -a api.fr.cloud.gov -o doi-onrr -s dev -v
            cf push dev-nrrd -f ./manifest.yml
  prod:
    docker:
      - image: cimg/node:16.20-browsers
    resource_class: xlarge
    steps:
      - checkout
      - restore_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
      - run:
          name: Install node dependencies
          command: npm install
      - save_cache:
          key: v3-node-modules-{{ checksum "package-lock.json" }}
          paths:
            - node_modules
      - run:
          name: "list generated downloads"
          command: |
            ls -lart static/downloads
           # rm static/downloads/downloads.json
      - aws-s3/sync:
          arguments: |
          aws-access-key-id: NPS_AWS_ACCESS_KEY
          aws-region: NPS_AWS_REGION
          aws-secret-access-key: NPS_AWS_SECRET_ACCESS_KEY
          from: 's3://${NPS_BUCKET_NAME}/downloads/'
          to: static/downloads/
      - run:
          name: "list generated downloads"
          command: |
            ls -lart static/downloads
            cat static/downloads/downloads.json
      - run:
          name: Build gatsby
          command: export GATSBY_HASURA_URI=https://hasura-prod.app.cloud.gov/v1/graphql && npm run build
      - run:
          name: deploy preview to cloud.gov
          command: |
            pwd && ls -l
            wget -q -U "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36" -O - https://packages.cloudfoundry.org/debian/cli.cloudfoundry.org.key | sudo apt-key add -
            echo "deb https://packages.cloudfoundry.org/debian stable main" | sudo tee /etc/apt/sources.list.d/cloudfoundry-cli.list
            sudo apt-get update
            sudo apt-get install cf8-cli
            cp Staticfile ./public
            # Set $CF_USERNAME and $CF_PASSWORD in CircleCI settings.
            # $CF_ORG, $CF_SPACE, and $APP_NAME can also be set in CircleCI settings or hardcoded here.
            cf api https://api.fr.cloud.gov
            cf auth "$CF_USERNAME" "$CF_PASSWORD"
            cf target -o doi-onrr -s prod
            #bash ./swap.sh
            cf push nrrd -f ./manifest.yml
  apply-database-changes:
    machine: 
      image: ubuntu-2204:current
    steps:
      - checkout
      - install-cf-cli
      - install-liquibase
      - install-java
      - install-postgres-client
      - run:
          name: Install cf connect-to-service plugin
          command: cf install-plugin -f https://github.com/cloud-gov/cf-service-connect/releases/download/1.1.0/cf-service-connect-linux-amd64
      - run:
          name: Login to cf cli
          command: cf login -a api.fr.cloud.gov -u "$CF_USERNAME" -p "$CF_PASSWORD" -o doi-onrr -s $CF_SPACE
      - run:
          name: Tunnel to database service
          command: |
            cf connect-to-service -no-client $CF_DB_APP $CF_DB_SERVICE > output &
            linecount=`cat output | wc -l | awk '{$1=$1};1'`
            stepcount=0
            while [ $linecount -lt 12 ] && [ $stepcount -lt 60 ];
            do 
                linecount=`cat output | wc -l | awk '{$1=$1};1'`
                stepcount=$((stepcount+1))
                sleep 1
            done
            echo $stepcount
            if [ $stepcount = 60 ]; then
              circleci-agent step halt
            fi
      - run:
          name: Set liquibase environment variables
          command: |
            echo export PORT=`cat output | grep Port: | cut -d ' ' -f2 |  tr -d '\n'` >> "$BASH_ENV"
            echo export HOST=`cat output | grep Host: | cut -d ' ' -f2 |  tr -d '\n'` >> "$BASH_ENV"
            echo export USERNAME=`cat output | grep Username: | cut -d ' ' -f2 |  tr -d '\n'` >> "$BASH_ENV"
            echo export PASSWORD=`cat output | grep Password: | cut -d ' ' -f2 |  tr -d '\n'` >> "$BASH_ENV"
            echo export DB_NAME=`cat output | grep Name: | cut -d ' ' -f2 |  tr -d '\n'` >> "$BASH_ENV"

            source "$BASH_ENV"

            echo export LIQUIBASE_COMMAND_USERNAME=$USERNAME >> "$BASH_ENV"
            echo export LIQUIBASE_COMMAND_PASSWORD=$PASSWORD >> "$BASH_ENV"
            echo export LIQUIBASE_COMMAND_URL=jdbc:postgresql://${HOST}:${PORT}/${DB_NAME} >> "$BASH_ENV"

            source "$BASH_ENV"
      - run:
          name: Backup database
          command: |
            mkdir -p /tmp/artifacts
            pg_dump postgres://${USERNAME}:${PASSWORD}@${HOST}:${PORT}/${DB_NAME} -Fc -f /tmp/artifacts/database_backup.pg || echo $?
      - store_artifacts:
          path: /tmp/artifacts/database_backup.pg
      - run:
          name: Call liquibase to update database
          no_output_timeout: 60m
          command: bash ~/project/.circleci/scripts/liquibase.sh
      - node/install
      - generate-downloads
  generate-data-downloads:
    machine: 
      image: ubuntu-2204:current
    steps:
      - checkout
      - install-cf-cli
      - install-postgres-client
      - run:
          name: Install cf connect-to-service plugin
          command: cf install-plugin -f https://github.com/cloud-gov/cf-service-connect/releases/download/1.1.0/cf-service-connect-linux-amd64
      - run:
          name: Login to cf cli
          command: cf login -a api.fr.cloud.gov -u "$CF_USERNAME" -p "$CF_PASSWORD" -o doi-onrr -s $CF_SPACE
      - run:
          name: Tunnel to database service
          command: |
            cf connect-to-service -no-client $CF_DB_APP $CF_DB_SERVICE > output &
            linecount=`cat output | wc -l | awk '{$1=$1};1'`
            stepcount=0
            while [ $linecount -lt 12 ] && [ $stepcount -lt 60 ];
            do 
                linecount=`cat output | wc -l | awk '{$1=$1};1'`
                stepcount=$((stepcount+1))
                sleep 1
            done
            echo $stepcount
            if [ $stepcount = 60 ]; then
              circleci-agent step halt
            fi
      - run:
          name: Set database environment variables
          command: |
            echo export PORT=`cat output | grep Port: | cut -d ' ' -f2 |  tr -d '\n'` >> "$BASH_ENV"
            echo export HOST=`cat output | grep Host: | cut -d ' ' -f2 |  tr -d '\n'` >> "$BASH_ENV"
            echo export USERNAME=`cat output | grep Username: | cut -d ' ' -f2 |  tr -d '\n'` >> "$BASH_ENV"
            echo export PASSWORD=`cat output | grep Password: | cut -d ' ' -f2 |  tr -d '\n'` >> "$BASH_ENV"
            echo export DB_NAME=`cat output | grep Name: | cut -d ' ' -f2 |  tr -d '\n'` >> "$BASH_ENV"

            source "$BASH_ENV"
      - node/install
      - generate-downloads

workflows:
  audits-workflow:
    jobs:
      - unit_tests:
          filters:
            branches:
              ignore:
                - master
                - staging
      - lint:
          filters:
            branches:
              ignore:
                - master
                - staging

      - lighthouse:
          filters:
            branches:
              ignore:
                - master
                - staging
  
  preview-workflow:
    jobs:
      - apply-database-changes:
          context:
            - org-global
            - nrrd
            - PREVIEW
          filters:
            branches:
              ignore:
                - master
                - dev
      - nrrd-preview:
          context:
            - nrrd
            - org-global
          requires:
            - apply-database-changes
          filters:
            branches:
              ignore:
                - master
                - dev

  prod-workflow:
    jobs:
      - apply-database-changes:
          context:
            - org-global
            - nrrd
            - PROD
          filters:
            branches:
              only: master
      - prod:
          context:
            - org-global
            - nrrd
          requires:
            - apply-database-changes
          filters:
            branches:
              only: master
  dev-workflow:
    jobs:
      - apply-database-changes:
          context:
            - org-global
            - nrrd
            - DEV
          filters:
            branches:
              only: dev
      - dev:
          context:
            - org-global
            - nrrd
            - DEV
          requires:
            - apply-database-changes
          filters:
            branches:
              only: dev
  generate_downloads:
    when: << pipeline.parameters.run_generate_downloads >>
    jobs:
      - generate-data-downloads:
          context:
            - org-global
            - nrrd
            - << pipeline.parameters.env_context >>
